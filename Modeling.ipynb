{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18f4124",
   "metadata": {},
   "source": [
    "# The model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7e81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814ce8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_csv(\"y_train\") \n",
    "y_val=pd.read_csv(\"y_val\")\n",
    "\n",
    "X_train_basic=pd.read_csv(\"X_train_basic\")\n",
    "X_val_basic=pd.read_csv(\"X_val_basic\")\n",
    "X_test_basic=pd.read_csv(\"X_test_basic\")\n",
    "\n",
    "y_predict_id=pd.read_csv('sample_submission.csv').drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cd1afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id\n",
      "0     1461\n",
      "1     1462\n",
      "2     1463\n",
      "3     1464\n",
      "4     1465\n",
      "...    ...\n",
      "1454  2915\n",
      "1455  2916\n",
      "1456  2917\n",
      "1457  2918\n",
      "1458  2919\n",
      "\n",
      "[1459 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb7dac",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3375398",
   "metadata": {},
   "source": [
    "To tune XGBoost, I plan to run through combinations of different parameters, recording the best solution (min error for cross validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc8fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575.763386819616\n",
      "40595.28536267404\n",
      "25.762297628077295\n"
     ]
    }
   ],
   "source": [
    "model=XGBRegressor()\n",
    "model.fit(X_train_basic,y_train)\n",
    "y_predict_train=model.predict(X_train_basic)\n",
    "y_predict_val=model.predict(X_val_basic)\n",
    "\n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)\n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2c8cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best_params=[]\\nbest_result=val_error\\nfor eta in range(10,30,5):\\n    print(eta)\\n    for max_depth in range(2,7):\\n        for min_child_weight in range(0,110,20):\\n            for reg_lambda in range(0,65,20):\\n                model=XGBRegressor(eta=eta/100,max_depth=max_depth ,min_child_weight=min_child_weight, reg_lambda=reg_lambda,subsample=0.7)\\n                model.fit(X_train_basic,y_train)\\n                y_predict_train=model.predict(X_train_basic)\\n                y_predict_val=model.predict(X_val_basic)\\n                \\n                train_error=mean_squared_error(y_predict_train,y_train,squared=False)\\n                val_error=mean_squared_error(y_predict_val,y_val,squared=False)\\n                \\n                if val_error<best_result:\\n                    best_result=val_error\\n                    best_params=[eta/100,max_depth,min_child_weight,reg_lambda]\\n                    print(best_params,best_result,val_error/train_error)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''best_params=[]\n",
    "best_result=val_error\n",
    "for eta in range(10,30,5):\n",
    "    print(eta)\n",
    "    for max_depth in range(2,7):\n",
    "        for min_child_weight in range(0,110,20):\n",
    "            for reg_lambda in range(0,65,20):\n",
    "                model=XGBRegressor(eta=eta/100,max_depth=max_depth ,min_child_weight=min_child_weight, reg_lambda=reg_lambda,subsample=0.7)\n",
    "                model.fit(X_train_basic,y_train)\n",
    "                y_predict_train=model.predict(X_train_basic)\n",
    "                y_predict_val=model.predict(X_val_basic)\n",
    "                \n",
    "                train_error=mean_squared_error(y_predict_train,y_train,squared=False)\n",
    "                val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "                \n",
    "                if val_error<best_result:\n",
    "                    best_result=val_error\n",
    "                    best_params=[eta/100,max_depth,min_child_weight,reg_lambda]\n",
    "                    print(best_params,best_result,val_error/train_error)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c831c2",
   "metadata": {},
   "source": [
    "Use this result to refine, can select any \"best result\" here to investigate, I  chose one that is over fitting less "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd55e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best_params=[0.15, 3, 20, 0]\\nbest_result=30830.12845229027\\nfor eta in range(13,18,1):\\n    print(eta)\\n    for max_depth in range(2,5):\\n        for min_child_weight in range(10,60,10):\\n            for reg_lambda in range(0,30,5):\\n                model=XGBRegressor(eta=eta/100,max_depth=max_depth ,min_child_weight=min_child_weight, reg_lambda=reg_lambda,subsample=0.7)\\n                model.fit(X_train_basic,y_train)\\n                y_predict_train=model.predict(X_train_basic)\\n                y_predict_val=model.predict(X_val_basic)\\n                \\n                train_error=mean_squared_error(y_predict_train,y_train,squared=False)\\n                val_error=mean_squared_error(y_predict_val,y_val,squared=False)\\n                \\n                if val_error<best_result:\\n                    best_result=val_error\\n                    best_params=[eta/100,max_depth,min_child_weight,reg_lambda]\\n                    print(best_params,best_result,val_error/train_error)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''best_params=[0.15, 3, 20, 0]\n",
    "best_result=30830.12845229027\n",
    "for eta in range(13,18,1):\n",
    "    print(eta)\n",
    "    for max_depth in range(2,5):\n",
    "        for min_child_weight in range(10,60,10):\n",
    "            for reg_lambda in range(0,30,5):\n",
    "                model=XGBRegressor(eta=eta/100,max_depth=max_depth ,min_child_weight=min_child_weight, reg_lambda=reg_lambda,subsample=0.7)\n",
    "                model.fit(X_train_basic,y_train)\n",
    "                y_predict_train=model.predict(X_train_basic)\n",
    "                y_predict_val=model.predict(X_val_basic)\n",
    "                \n",
    "                train_error=mean_squared_error(y_predict_train,y_train,squared=False)\n",
    "                val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "                \n",
    "                if val_error<best_result:\n",
    "                    best_result=val_error\n",
    "                    best_params=[eta/100,max_depth,min_child_weight,reg_lambda]\n",
    "                    print(best_params,best_result,val_error/train_error)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9607a034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for min_child_weight in range(9,12):\\n    print(min_child_weight)\\n    for reg_lambda in range(5,11,1):\\n        model=XGBRegressor(eta=0.13,max_depth=4 ,min_child_weight=min_child_weight, reg_lambda=reg_lambda)\\n        model.fit(X_train_basic,y_train)\\n        y_predict_train=model.predict(X_train_basic)\\n        y_predict_val=model.predict(X_val_basic)\\n                \\n        train_error=mean_squared_error(y_predict_train,y_train,squared=False)\\n        val_error=mean_squared_error(y_predict_val,y_val,squared=False)\\n                \\n        \\n       \\n        params=[0.13,4,min_child_weight,reg_lambda]\\n        print(params,val_error,val_error/train_error)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''for min_child_weight in range(9,12):\n",
    "    print(min_child_weight)\n",
    "    for reg_lambda in range(5,11,1):\n",
    "        model=XGBRegressor(eta=0.13,max_depth=4 ,min_child_weight=min_child_weight, reg_lambda=reg_lambda)\n",
    "        model.fit(X_train_basic,y_train)\n",
    "        y_predict_train=model.predict(X_train_basic)\n",
    "        y_predict_val=model.predict(X_val_basic)\n",
    "                \n",
    "        train_error=mean_squared_error(y_predict_train,y_train,squared=False)\n",
    "        val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "                \n",
    "        \n",
    "       \n",
    "        params=[0.13,4,min_child_weight,reg_lambda]\n",
    "        print(params,val_error,val_error/train_error)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb33ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13986.915306486933\n",
      "30727.758413990563\n",
      "2.196893149109115\n"
     ]
    }
   ],
   "source": [
    "model=XGBRegressor(eta=0.13,max_depth=5 ,min_child_weight=10, reg_lambda=5,subsample=0.7)\n",
    "model.fit(X_train_basic,y_train)\n",
    "y_predict_train=model.predict(X_train_basic)\n",
    "y_predict_val=model.predict(X_val_basic)\n",
    "                \n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)                \n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33f3f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=y_predict_id.join(pd.DataFrame(model.predict(X_test_basic)))\n",
    "y_predict.columns=['Id','SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2a20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e6e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict.to_csv(\"basic_prediction\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b46b19",
   "metadata": {},
   "source": [
    "This basic prediction gave a score of 0.14057 with (eta=0.25,max_depth=5 ,min_child_weight=65, reg_lambda=15)\n",
    "\n",
    "(eta=0.3,max_depth=3 ,min_child_weight=100, reg_lambda=50) gave 0.14747 (more underfit less over fit) <br>\n",
    "(eta=0.25,max_depth=4 ,min_child_weight=50, reg_lambda=50) gave 0.13882 (1.596 middle ground between the two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6e6ae",
   "metadata": {},
   "source": [
    "(eta=0.25,max_depth=4 ,min_child_weight=50, reg_lambda=50) 0.13882\n",
    "19615.815869522346\n",
    "31314.14893194564\n",
    "1.5963724955534135\n",
    "\n",
    "try [13, 4, 10, 0] it gave best score! 0.13784\n",
    "[0.13, 4, 10, 5] gave 0.13630 score, slightly less over fit \n",
    "\n",
    "(eta=0.13,max_depth=5 ,min_child_weight=10, reg_lambda=5,subsample=0.7) gave 0.13526"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af0d62",
   "metadata": {},
   "source": [
    "In summary, I used a basic form of grid search to check experiment with different parameters. To improve this in the future, I will learn a more advanced approach and apply it a little more systematically but as a first attempt this was an interesting way to experiment with improving my model. Though basic, I did get a useful improvement in my results and moved up the kaggle leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65580f47",
   "metadata": {},
   "source": [
    "# Random Forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df31697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(1168, 1)\n",
      "[145000 237000 193500 ... 251000 260000 179900]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_train))\n",
    "\n",
    "y_train.to_numpy()\n",
    "\n",
    "print(type(y_train.to_numpy().ravel()))\n",
    "print(np.shape(y_train.to_numpy()))\n",
    "print(y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1bce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       ...\n",
      "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=299) Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       ...\n",
      "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
      "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
      "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=299)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_basic.columns,X_val_basic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65097781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12861.140954016148\n",
      "31856.641961048947\n",
      "2.4769685733909226\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestRegressor(max_depth=9, random_state=42)\n",
    "RF.fit(X_train_basic,np.ravel(y_train))\n",
    "y_predict_train=RF.predict(X_train_basic)\n",
    "y_predict_val=RF.predict(X_val_basic)\n",
    "                \n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)                \n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d92db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_RF=y_predict_id.join(pd.DataFrame(RF.predict(X_test_basic)))\n",
    "y_predict_RF.columns=['Id','SalePrice']\n",
    "\n",
    "y_predict_RF.to_csv(\"basic_RF\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a2838",
   "metadata": {},
   "source": [
    "Score: 0.14963 for the max_depth=10 random forrest regressor for a random instance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342853c3",
   "metadata": {},
   "source": [
    "After Tuning my Random forrest model, I found I was not able to get an improvement over my XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e34ced",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d12e175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13157.550035121658\n",
      "30426.630841787824\n",
      "2.3124845248978367\n"
     ]
    }
   ],
   "source": [
    "y_predict_val=(3*model.predict(X_val_basic)+RF.predict(X_val_basic))/4\n",
    "y_predict_train=(3*model.predict(X_train_basic)+RF.predict(X_train_basic))/4\n",
    "\n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)                \n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f44704",
   "metadata": {},
   "source": [
    "This was interesting to experiment with but ultimately I will need to learn a more systematic apporach to apply this usefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055fb65",
   "metadata": {},
   "source": [
    "# Using linear feature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de893472",
   "metadata": {},
   "source": [
    "Here I experimented with using a linear reggression model to generate a feature to use in my XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47c3c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_lin=pd.read_csv(\"X_train_lin\")\n",
    "X_val_lin=pd.read_csv(\"X_val_lin\")\n",
    "X_test_lin=pd.read_csv(\"X_test_lin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7cd5cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14392.838349945281\n",
      "31718.805841795303\n",
      "2.203790876447653\n"
     ]
    }
   ],
   "source": [
    "model=XGBRegressor(eta=0.13,max_depth=5 ,min_child_weight=10, reg_lambda=5,subsample=0.7)\n",
    "model.fit(X_train_lin,y_train)\n",
    "y_predict_train=model.predict(X_train_lin)\n",
    "y_predict_val=model.predict(X_val_lin)\n",
    "                \n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)                \n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d6f64",
   "metadata": {},
   "source": [
    "# Using total Square foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3d6d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SF=pd.read_csv(\"X_train_SF\")\n",
    "X_val_SF=pd.read_csv(\"X_val_SF\")\n",
    "X_test_SF=pd.read_csv(\"X_test_SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6c4c37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16831.0530080345\n",
      "30413.304601454627\n",
      "1.8069757481564865\n"
     ]
    }
   ],
   "source": [
    "model=XGBRegressor(eta=0.15,max_depth=8 ,min_child_weight=20, reg_lambda=20,subsample=0.7)\n",
    "model.fit(X_train_SF,y_train)\n",
    "y_predict_train=model.predict(X_train_SF)\n",
    "y_predict_val=model.predict(X_val_SF)\n",
    "                \n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)                \n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec2da09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=y_predict_id.join(pd.DataFrame(model.predict(X_test_SF)))\n",
    "y_predict.columns=['Id','SalePrice']\n",
    "y_predict.to_csv(\"SF_prediction\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d03d8",
   "metadata": {},
   "source": [
    "0.13370 scored with eta=0.15,max_depth=5 ,min_child_weight=20, reg_lambda=15,subsample=0.7\n",
    "0.13430 scored with eta=0.15,max_depth=8 ,min_child_weight=20, reg_lambda=15,subsample=0.7\n",
    "\n",
    "Score: 0.13639 with (eta=0.15,max_depth=8 ,min_child_weight=20, reg_lambda=20,subsample=0.7) and garage included in SF <br>\n",
    "0.13365 (eta=0.15,max_depth=8 ,min_child_weight=20, reg_lambda=20,subsample=0.7) with garage excluded from SF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e85ceb",
   "metadata": {},
   "source": [
    "My best result Came from using this model and engineered features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3abdc1",
   "metadata": {},
   "source": [
    "# Using quality x square footage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3d6cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eng=pd.read_csv(\"X_train_eng\")\n",
    "X_val_eng=pd.read_csv(\"X_val_eng\")\n",
    "X_test_eng=pd.read_csv(\"X_test_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63c46c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20219.565102284116\n",
      "31553.355615157026\n",
      "1.5605358204065716\n"
     ]
    }
   ],
   "source": [
    "model=XGBRegressor(eta=0.15,max_depth=3 ,min_child_weight=20, reg_lambda=15,subsample=0.7)\n",
    "model.fit(X_train_eng,y_train)\n",
    "y_predict_train=model.predict(X_train_eng)\n",
    "y_predict_val=model.predict(X_val_eng)\n",
    "                \n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)                \n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8c7d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=y_predict_id.join(pd.DataFrame(model.predict(X_test_eng)))\n",
    "y_predict.columns=['Id','SalePrice']\n",
    "y_predict.to_csv(\"eng_prediction\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a991e3b",
   "metadata": {},
   "source": [
    "0.13668 (eta=0.15,max_depth=3 ,min_child_weight=10, reg_lambda=0,subsample=0.7) and engineered data\n",
    "0.13382 (eta=0.15,max_depth=4 ,min_child_weight=20, reg_lambda=20,subsample=0.7) more under fit solution\n",
    "0.13573 (eta=0.15,max_depth=3 ,min_child_weight=20, reg_lambda=15,subsample=0.7) even more underfit, slightly worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1293696",
   "metadata": {},
   "source": [
    "This new feature was interesting to create, but ultimately it did not improve the model and was probably just causing the model to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4921e2",
   "metadata": {},
   "source": [
    "# Random forrest with engineered data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4908f",
   "metadata": {},
   "source": [
    "After experimenting with my engineered data, I still found the Random forrest model to be less effective than XGBoost. I would be interested to see if I could close this gap with better tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89a325fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10839.278982510428\n",
      "30330.343066430265\n",
      "2.7981882480716087\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestRegressor(n_estimators=200,max_depth=15,max_features=0.9,min_impurity_decrease=50, random_state=42)\n",
    "RF.fit(X_train_eng,np.ravel(y_train))\n",
    "y_predict_train=RF.predict(X_train_eng)\n",
    "y_predict_val=RF.predict(X_val_eng)\n",
    "                \n",
    "train_error=mean_squared_error(y_predict_train,y_train,squared=False)                \n",
    "val_error=mean_squared_error(y_predict_val,y_val,squared=False)\n",
    "print(train_error)\n",
    "print(val_error)\n",
    "print(val_error/train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f746f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_RF=y_predict_id.join(pd.DataFrame(RF.predict(X_test_eng)))\n",
    "y_predict_RF.columns=['Id','SalePrice']\n",
    "\n",
    "y_predict_RF.to_csv(\"eng_RF\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e436db2",
   "metadata": {},
   "source": [
    "0.16059 (n_estimators=200,max_depth=5,max_features=0.9,min_impurity_decrease=50, random_state=42) way too under fit! \n",
    "I seem to be having issues with the model under and over fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce24167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
