This is my attempt at the Kaggle House Prices- Advanced Regression techniques competition. 

My best score was 0.13316, and I achived this by engineering a total square footage feature and tuning an XGBoost model. My goal for this competition was 
to learn about feature engineering and hyper parameter tuning by having fun playing around with several combinations of each. 
With this in mind, I experiemnted with a few different models and ideas for new features. Ultimately XGBoost and a simple a simple feature for the total 
square footage gave the best result. It was interesting to apply knowledge I had gained from the Deeplearning.AI course on machine learning to a real situation,
where I could address issues like overfitting myself. 
